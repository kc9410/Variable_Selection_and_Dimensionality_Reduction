{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터: Malwares Classification 데이터 셋\n",
    "- Malware를 분류하는 것을 목적으로 하는 데이터 셋\n",
    "- 총 68개의 독립 변수를 통해 종속 변수(Not Malware=0, Malware=1)를 예측해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./data/Malwares Classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_lfanew</th>\n",
       "      <th>NumberOfSections</th>\n",
       "      <th>CreationYear</th>\n",
       "      <th>FH_char0</th>\n",
       "      <th>FH_char1</th>\n",
       "      <th>...</th>\n",
       "      <th>LoaderFlags</th>\n",
       "      <th>sus_sections</th>\n",
       "      <th>non_sus_sections</th>\n",
       "      <th>packer</th>\n",
       "      <th>E_text</th>\n",
       "      <th>E_data</th>\n",
       "      <th>filesize</th>\n",
       "      <th>E_file</th>\n",
       "      <th>fileinfo</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.603616</td>\n",
       "      <td>5.443362</td>\n",
       "      <td>1181520.0</td>\n",
       "      <td>6.627552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.205926</td>\n",
       "      <td>2.123522</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>5.318221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.238000</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>57872.0</td>\n",
       "      <td>6.507758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95616.0</td>\n",
       "      <td>4.575092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.355626</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>48128.0</td>\n",
       "      <td>5.545531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_cblp  e_cp  e_cparhdr  e_maxalloc   e_sp  e_lfanew  NumberOfSections  \\\n",
       "0   144.0   3.0        4.0     65535.0  184.0     256.0               4.0   \n",
       "1   144.0   3.0        4.0     65535.0  184.0     184.0               4.0   \n",
       "2   144.0   3.0        4.0     65535.0  184.0     272.0               5.0   \n",
       "3   144.0   3.0        4.0     65535.0  184.0     184.0               1.0   \n",
       "4   144.0   3.0        4.0     65535.0  184.0     224.0               5.0   \n",
       "\n",
       "   CreationYear  FH_char0  FH_char1  ...  LoaderFlags  sus_sections  \\\n",
       "0           1.0       0.0       1.0  ...          1.0           1.0   \n",
       "1           1.0       0.0       1.0  ...          1.0           1.0   \n",
       "2           1.0       0.0       1.0  ...          1.0           1.0   \n",
       "3           1.0       0.0       1.0  ...          1.0           0.0   \n",
       "4           1.0       0.0       1.0  ...          1.0           1.0   \n",
       "\n",
       "   non_sus_sections  packer    E_text    E_data   filesize    E_file  \\\n",
       "0               3.0     0.0  6.603616  5.443362  1181520.0  6.627552   \n",
       "1               3.0     0.0  5.205926  2.123522     7680.0  5.318221   \n",
       "2               4.0     0.0  6.238000  3.380859    57872.0  6.507758   \n",
       "3               1.0     0.0  0.000000  0.000000    95616.0  4.575092   \n",
       "4               4.0     0.0  6.355626  0.702621    48128.0  5.545531   \n",
       "\n",
       "   fileinfo  class  \n",
       "0       1.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       1.0    0.0  \n",
       "3       1.0    0.0  \n",
       "4       1.0    0.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['e_cblp', 'e_cp', 'e_cparhdr', 'e_maxalloc', 'e_sp', 'e_lfanew',\n",
      "       'NumberOfSections', 'CreationYear', 'FH_char0', 'FH_char1', 'FH_char2',\n",
      "       'FH_char3', 'FH_char4', 'FH_char5', 'FH_char6', 'FH_char7', 'FH_char8',\n",
      "       'FH_char9', 'FH_char10', 'FH_char11', 'FH_char12', 'FH_char13',\n",
      "       'FH_char14', 'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode',\n",
      "       'SizeOfInitializedData', 'SizeOfUninitializedData',\n",
      "       'AddressOfEntryPoint', 'BaseOfCode', 'BaseOfData', 'ImageBase',\n",
      "       'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion',\n",
      "       'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion',\n",
      "       'MajorSubsystemVersion', 'MinorSubsystemVersion', 'SizeOfImage',\n",
      "       'SizeOfHeaders', 'CheckSum', 'Subsystem', 'OH_DLLchar0', 'OH_DLLchar1',\n",
      "       'OH_DLLchar2', 'OH_DLLchar3', 'OH_DLLchar4', 'OH_DLLchar5',\n",
      "       'OH_DLLchar6', 'OH_DLLchar7', 'OH_DLLchar8', 'OH_DLLchar9',\n",
      "       'OH_DLLchar10', 'SizeOfStackReserve', 'SizeOfStackCommit',\n",
      "       'SizeOfHeapReserve', 'SizeOfHeapCommit', 'LoaderFlags', 'sus_sections',\n",
      "       'non_sus_sections', 'packer', 'E_text', 'E_data', 'filesize', 'E_file',\n",
      "       'fileinfo', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 분리 및 불필요한 변수 제거\n",
    "data = data.dropna(axis=0)\n",
    "labels = data.loc[:,'class']\n",
    "X_data = data.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Split\n",
    "- 무작위 추출 방식을 활용하여 전체 데이터 셋을 Train, Validation, Test로 구분함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# train 데이터를 기반으로 train/test 데이터에 대하여 standard scaling 적용 (평균 0, 분산 1) \n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.transform(X_train),columns=X_train.columns,index=X_train.index)\n",
    "X_val   = pd.DataFrame(scaler.transform(X_val),columns=X_val.columns,index=X_val.index)\n",
    "X_test  = pd.DataFrame(scaler.transform(X_test),columns=X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 후 평균: -4.116455523646154e-16\n",
      "정규화 후 분산: 1.0000000000000127\n"
     ]
    }
   ],
   "source": [
    "print(\"정규화 후 평균:\", np.mean(X_train.iloc[:,5]))\n",
    "print(\"정규화 후 분산:\", np.var(X_train.iloc[:,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 단순 모델 학습 및 평가\n",
    "- 변수 선택법을 적용하지 않았을 때, 선형 회귀 모델과 로지스틱 회귀 모델을 학습하고 그 성능을 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선형 회귀 학습\n",
    "line_fitter = LinearRegression()\n",
    "line_fitter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀 학습\n",
    "logistic_fitter = LogisticRegression(solver=\"lbfgs\")\n",
    "logistic_fitter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy 측정\n",
    "def Acc(pred,label,pri=True):\n",
    "    if pri:\n",
    "        print(\"Accuracy:\",np.round(np.sum(pred==label)/len(label)*100,1),\"%\")\n",
    "    return np.sum(pred==label)/len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형 회귀 모델 예측 결과\n",
    "line_pred_test = line_fitter.predict(X_test)\n",
    "#로지스틱 회귀 모델 예측 결과\n",
    "logistic_pred_test = logistic_fitter.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형 회귀 모델\n",
      "Accuracy: 92.5 %\n",
      "로지스틱 회귀 모델\n",
      "Accuracy: 95.2 %\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 성능 평가\n",
    "print(\"선형 회귀 모델\")\n",
    "linear_all = Acc(line_pred_test>0.5,y_test)\n",
    "print(\"로지스틱 회귀 모델\")\n",
    "logistic_all = Acc(logistic_pred_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611324376199616\n",
      "0.9520153550863724\n"
     ]
    }
   ],
   "source": [
    "#logistic 모델 내장 함수 사용\n",
    "print(logistic_fitter.score(X_train, y_train))\n",
    "print(logistic_fitter.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-1. 변수 선택법: 전진 선택법, 후진 소거법, 단계적 선택법\n",
    "- 전진 선택법, 후진 소거법, 그리고 단계적 선택법을 적용하여 모델링 변수를 선별함\n",
    "- 선형 회귀 모델과 로직스틱 모델을 통해 각 선택법에 따른 성능 차이를 확인함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. 전진 선택법\n",
    "- 변수가 하나도 없는 상태로부터 시작해서 1개씩 변수를 추가하는 기법\n",
    "- 적합도 함수를 활용해 해당 함수 값이 가장 높은 변수를 선택하는 방식\n",
    "- Stopping Criteria를 통해 변수 선택을 중단함\n",
    "    - 변수를 추가하여도 더 이상 성능이 증가하지 않음\n",
    "    - 성능이 기준 이상을 만족\n",
    "    - 변수의 개수가 일정 개수를 초과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_selection(model, X_train,y_train,X_val,y_val,direction):\n",
    "    var = list(range(len(X_train.columns)))\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    if direction == \"forward\":\n",
    "        inmodel  =[]\n",
    "        outmodel = var\n",
    "        while outmodel and current_score==best_new_score:\n",
    "            score_candidate = []\n",
    "            for candidate in outmodel:\n",
    "                temp_var = inmodel + [candidate]\n",
    "                Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                model.fit(Temp_X_train,y_train)\n",
    "                prediction = model.predict(Temp_X_val)\n",
    "                score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                score_candidate.append((score,candidate))\n",
    "              \n",
    "            score_candidate.sort()\n",
    "            best_new_score, best_candidate = score_candidate.pop()\n",
    "            if current_score>=best_new_score:\n",
    "            #if current_score>=best_new_score and len(inmodel)>=15:\n",
    "            #if current_score>=best_new_score and best_new_score>=0.943:\n",
    "            #if current_score>=best_new_score or len(inmodel)==5:\n",
    "                print(\"Finish:\", inmodel)\n",
    "                break\n",
    "            else:\n",
    "                outmodel.remove(best_candidate)\n",
    "                inmodel.append(best_candidate)\n",
    "                current_score = best_new_score\n",
    "            \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round(score*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "        \n",
    "        return model, inmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\n",
      "[20, 46]\n",
      "[20, 46, 3]\n",
      "[20, 46, 3, 18]\n",
      "[20, 46, 3, 18, 65]\n",
      "[20, 46, 3, 18, 65, 43]\n",
      "[20, 46, 3, 18, 65, 43, 67]\n",
      "[20, 46, 3, 18, 65, 43, 67, 34]\n",
      "Finish: [20, 46, 3, 18, 65, 43, 67, 34]\n",
      "Best Validation Acc: 93.3 %\n",
      "선택된 변수의 개수: 8 개\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델에 대한 전진 선택법 적용 결과\n",
    "model, inmodel = variable_selection(LinearRegression(), X_train,y_train,X_val,y_val,direction=\"forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형 회귀 모델-전진 선택법\n",
      "Accuracy: 91.6 %\n",
      "선택된 변수 개수: 8\n",
      "Acc 증감: -1.0 %\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델 전진 선택법 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"선형 회귀 모델-전진 선택법\")\n",
    "linear_forward = Acc(pred_test>0.5,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((linear_forward-linear_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\n",
      "[20, 46]\n",
      "[20, 46, 65]\n",
      "[20, 46, 65, 43]\n",
      "[20, 46, 65, 43, 67]\n",
      "[20, 46, 65, 43, 67, 22]\n",
      "[20, 46, 65, 43, 67, 22, 55]\n",
      "[20, 46, 65, 43, 67, 22, 55, 58]\n",
      "Finish: [20, 46, 65, 43, 67, 22, 55, 58]\n",
      "Best Validation Acc: 96.0 %\n",
      "선택된 변수의 개수: 8 개\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델에 대한 전진 선택법 적용 결과\n",
    "model, inmodel = variable_selection(LogisticRegression(solver=\"lbfgs\"), X_train,y_train,X_val,y_val,direction=\"forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델-전진 선택법\n",
      "Accuracy: 92.7 %\n",
      "선택된 변수 개수: 8\n",
      "Acc 증감: -2.5 %\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델 전진 선택법 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"로지스틱 회귀 모델-전진 선택법\")\n",
    "logistic_forward = Acc(pred_test,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((logistic_forward-logistic_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. 후진 소거법\n",
    "- 전체 변수로부터 시작해서 하나씩 변수를 제거하는 방식\n",
    "- 적합도 함수를 활용해 해당 함수 값이 가장 높은 변수를 제거하는 방식\n",
    "- Stopping Criteria를 통해 변수 선택을 중단함\n",
    "    - 변수를 제거하여도 더 이상 증가하지 않음\n",
    "    - 변수의 개수가 일정 개수 이하여야 stop 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_selection(model, X_train,y_train,X_val,y_val,direction):\n",
    "    var = list(range(len(X_train.columns)))\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    if direction == \"backward\":\n",
    "        inmodel  = var\n",
    "        outmodel = []\n",
    "        while inmodel and current_score==best_new_score:\n",
    "            score_candidate = []\n",
    "            for candidate in inmodel:\n",
    "                temp_var = inmodel.copy()\n",
    "                temp_var.remove(candidate)\n",
    "                Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                model.fit(Temp_X_train,y_train)\n",
    "                prediction = model.predict(Temp_X_val)\n",
    "                score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                score_candidate.append((score,candidate))\n",
    "              \n",
    "            score_candidate.sort()\n",
    "            best_new_score, best_candidate = score_candidate.pop()\n",
    "            \n",
    "            if current_score>=best_new_score:\n",
    "            #if current_score>=best_new_score and len(inmodel)>=15:\n",
    "            #if current_score>=best_new_score and best_new_score>=0.943:\n",
    "            #if current_score>=best_new_score or len(inmodel)==5:\n",
    "                print(\"Finish:\", inmodel)\n",
    "                break\n",
    "            else:\n",
    "                outmodel.append(best_candidate)\n",
    "                inmodel.remove(best_candidate)\n",
    "                current_score = best_new_score\n",
    "                \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round(score*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "        \n",
    "        return model, inmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "Finish: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "Best Validation Acc: 94.8 %\n",
      "선택된 변수의 개수: 63 개\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델에 대한 후진 소거법 적용 결과\n",
    "model, inmodel = variable_selection(LinearRegression(), X_train,y_train,X_val,y_val,direction=\"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형 회귀 모델-후진 소거법\n",
      "Accuracy: 92.5 %\n",
      "선택된 변수 개수: 63\n",
      "Acc 증감: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델 후진 소거법 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"선형 회귀 모델-후진 소거법\")\n",
    "linear_backward = Acc(pred_test>0.5,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((linear_backward-linear_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "Finish: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "Best Validation Acc: 97.3 %\n",
      "선택된 변수의 개수: 63 개\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델에 대한 전진 선택법 적용 결과\n",
    "model, inmodel = variable_selection(LogisticRegression(solver=\"lbfgs\",max_iter=300), X_train,y_train,X_val,y_val,direction=\"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델-후진 소거법\n",
      "Accuracy: 95.4 %\n",
      "선택된 변수 개수: 63\n",
      "Acc 증감: 0.2 %\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델 후진 소거법 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"로지스틱 회귀 모델-후진 소거법\")\n",
    "logistic_backward = Acc(pred_test,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((logistic_backward-logistic_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. 단계적 선택법\n",
    "- 전진 선택법과 마찬가지로 변수가 하나도 없는 상태에서 시작\n",
    "- 전진 선택법과 후진 선택법을 모두 적용하여 적합도 함수를 계산함\n",
    "- 적합도 함수가 가장 높은 경우로 변수 선택 or 제거를 진행함\n",
    "- Stopping Criteria를 통해 변수 선택을 중단함\n",
    "    - 변수를 추가하거나 제거하여도 더 이상 성능이 증가하지 않음\n",
    "    - 성능이 기준 이상을 만족\n",
    "    - 변수의 개수가 일정 개수를 초과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_selection(model, X_train,y_train,X_val,y_val,direction):\n",
    "    var = list(range(len(X_train.columns)))\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    if direction == \"step\":\n",
    "        inmodel  =[]\n",
    "        outmodel = var\n",
    "        stop = 0\n",
    "        count = 0\n",
    "        forward = 0\n",
    "        backward = 0\n",
    "        while outmodel and stop<2:\n",
    "            score_candidate = []\n",
    "            count=count+1\n",
    "            if count%2==1 or count==2:\n",
    "                for candidate in outmodel:\n",
    "                    temp_var = inmodel + [candidate]\n",
    "                    Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                    Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                    model.fit(Temp_X_train,y_train)\n",
    "                    prediction = model.predict(Temp_X_val)\n",
    "                    score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                    score_candidate.append((score,candidate))\n",
    "              \n",
    "                score_candidate.sort()\n",
    "                best_new_score, best_candidate = score_candidate.pop()\n",
    "                if current_score<best_new_score:\n",
    "                    print(\"succes forward\")\n",
    "                    outmodel.remove(best_candidate)\n",
    "                    inmodel.append(best_candidate)\n",
    "                    current_score = best_new_score\n",
    "                    stop=0\n",
    "                    forward = forward+1\n",
    "                else:\n",
    "                    print(\"falis forward\")\n",
    "                    stop=stop+1\n",
    "            else:\n",
    "                for candidate in inmodel:\n",
    "                    temp_var = inmodel.copy()\n",
    "                    temp_var.remove(candidate)\n",
    "                    Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                    Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                    model.fit(Temp_X_train,y_train)\n",
    "                    prediction = model.predict(Temp_X_val)\n",
    "                    score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                    score_candidate.append((score,candidate))\n",
    "                \n",
    "                score_candidate.sort()\n",
    "                best_new_score, best_candidate = score_candidate.pop()\n",
    "                    \n",
    "                if current_score<best_new_score:\n",
    "                    print(\"succes backward\")\n",
    "                    outmodel.append(best_candidate)\n",
    "                    inmodel.remove(best_candidate)\n",
    "                    current_score = best_new_score\n",
    "                    stop=0\n",
    "                    backward = backward+1\n",
    "                else:\n",
    "                    print(\"fails backward\")\n",
    "                    stop=stop+1\n",
    "                \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round((score)*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "        print(\"succes forward:\", forward)\n",
    "        print(\"succes backward:\", backward)\n",
    "        \n",
    "        return model, inmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succes forward\n",
      "[20]\n",
      "succes forward\n",
      "[20, 46]\n",
      "succes forward\n",
      "[20, 46, 3]\n",
      "fails backward\n",
      "[20, 46, 3]\n",
      "succes forward\n",
      "[20, 46, 3, 18]\n",
      "fails backward\n",
      "[20, 46, 3, 18]\n",
      "succes forward\n",
      "[20, 46, 3, 18, 65]\n",
      "fails backward\n",
      "[20, 46, 3, 18, 65]\n",
      "succes forward\n",
      "[20, 46, 3, 18, 65, 43]\n",
      "fails backward\n",
      "[20, 46, 3, 18, 65, 43]\n",
      "succes forward\n",
      "[20, 46, 3, 18, 65, 43, 67]\n",
      "fails backward\n",
      "[20, 46, 3, 18, 65, 43, 67]\n",
      "succes forward\n",
      "[20, 46, 3, 18, 65, 43, 67, 34]\n",
      "fails backward\n",
      "[20, 46, 3, 18, 65, 43, 67, 34]\n",
      "falis forward\n",
      "[20, 46, 3, 18, 65, 43, 67, 34]\n",
      "Best Validation Acc: 93.3 %\n",
      "선택된 변수의 개수: 8 개\n",
      "succes forward: 8\n",
      "succes backward: 0\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델에 대한 단계적 선택법 적용 결과\n",
    "model, inmodel = variable_selection(LinearRegression(), X_train,y_train,X_val,y_val,direction=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형 회귀 모델-단계적 소거법\n",
      "Accuracy: 91.6 %\n",
      "선택된 변수 개수: 8\n",
      "Acc 증감: -1.0 %\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델 단계적 선택법 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"선형 회귀 모델-단계적 소거법\")\n",
    "linear_step = Acc(pred_test>0.5,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((linear_step-linear_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succes forward\n",
      "[20]\n",
      "succes forward\n",
      "[20, 46]\n",
      "succes forward\n",
      "[20, 46, 65]\n",
      "fails backward\n",
      "[20, 46, 65]\n",
      "succes forward\n",
      "[20, 46, 65, 43]\n",
      "fails backward\n",
      "[20, 46, 65, 43]\n",
      "succes forward\n",
      "[20, 46, 65, 43, 67]\n",
      "fails backward\n",
      "[20, 46, 65, 43, 67]\n",
      "succes forward\n",
      "[20, 46, 65, 43, 67, 22]\n",
      "fails backward\n",
      "[20, 46, 65, 43, 67, 22]\n",
      "succes forward\n",
      "[20, 46, 65, 43, 67, 22, 55]\n",
      "fails backward\n",
      "[20, 46, 65, 43, 67, 22, 55]\n",
      "succes forward\n",
      "[20, 46, 65, 43, 67, 22, 55, 58]\n",
      "fails backward\n",
      "[20, 46, 65, 43, 67, 22, 55, 58]\n",
      "falis forward\n",
      "[20, 46, 65, 43, 67, 22, 55, 58]\n",
      "Best Validation Acc: 0.9596928982725528\n",
      "선택된 변수의 개수: 8 개\n",
      "succes forward: 8\n",
      "succes backward: 0\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델에 대한 단계적 선택법 적용 결과\n",
    "model, inmodel = variable_selection(LogisticRegression(solver=\"lbfgs\",max_iter=300), X_train,y_train,X_val,y_val,direction=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델-단계적 선택법\n",
      "Accuracy: 92.7 %\n",
      "선택된 변수 개수: 8\n",
      "Acc 증감: -2.5 %\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델 단계적 선택법 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"로지스틱 회귀 모델-단계적 선택법\")\n",
    "logistic_step = Acc(pred_test,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((logistic_step-logistic_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_selection(model, X_train,y_train,X_val,y_val,direction):\n",
    "    var = list(range(len(X_train.columns)))\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    if direction == \"step2\":\n",
    "        inmodel  = var\n",
    "        outmodel = []\n",
    "        stop = 0\n",
    "        count = 0\n",
    "        forward = 0\n",
    "        backward = 0\n",
    "        while inmodel and stop<2:\n",
    "            score_candidate = []\n",
    "            count=count+1\n",
    "            if count%2==0 and count!=2:\n",
    "                for candidate in outmodel:\n",
    "                    temp_var = inmodel + [candidate]\n",
    "                    Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                    Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                    model.fit(Temp_X_train,y_train)\n",
    "                    prediction = model.predict(Temp_X_val)\n",
    "                    score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                    score_candidate.append((score,candidate))\n",
    "              \n",
    "                score_candidate.sort()\n",
    "                best_new_score, best_candidate = score_candidate.pop()\n",
    "                if current_score<best_new_score:\n",
    "                    print(\"succes forward\")\n",
    "                    outmodel.remove(best_candidate)\n",
    "                    inmodel.append(best_candidate)\n",
    "                    current_score = best_new_score\n",
    "                    stop=0\n",
    "                    forward = forward+1\n",
    "                else:\n",
    "                    print(\"falis forward\")\n",
    "                    stop=stop+1\n",
    "            else:\n",
    "                for candidate in inmodel:\n",
    "                    temp_var = inmodel.copy()\n",
    "                    temp_var.remove(candidate)\n",
    "                    Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                    Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                    model.fit(Temp_X_train,y_train)\n",
    "                    prediction = model.predict(Temp_X_val)\n",
    "                    score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                    score_candidate.append((score,candidate))\n",
    "                \n",
    "                score_candidate.sort()\n",
    "                best_new_score, best_candidate = score_candidate.pop()\n",
    "                    \n",
    "                if current_score<best_new_score:\n",
    "                    print(\"succes backward\")\n",
    "                    outmodel.append(best_candidate)\n",
    "                    inmodel.remove(best_candidate)\n",
    "                    current_score = best_new_score\n",
    "                    stop=0\n",
    "                    backward = backward+1\n",
    "                else:\n",
    "                    print(\"fails backward\")\n",
    "                    stop=stop+1\n",
    "                \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round((score)*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "        print(\"succes forward:\", forward)\n",
    "        print(\"succes backward:\", backward)\n",
    "        \n",
    "        return model, inmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "falis forward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "falis forward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "falis forward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "fails backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\n",
      "Best Validation Acc: 94.8 %\n",
      "선택된 변수의 개수: 63 개\n",
      "succes forward: 0\n",
      "succes backward: 5\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델에 대한 단계적 선택법2 적용 결과\n",
    "model, inmodel = variable_selection(LinearRegression(), X_train,y_train,X_val,y_val,direction=\"step2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형 회귀 모델-단계적 선택법2\n",
      "Accuracy: 92.5 %\n",
      "선택된 변수 개수: 63\n",
      "Acc 증감: 0.0\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀 모델 단계적 선택법2 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"선형 회귀 모델-단계적 선택법2\")\n",
    "linear_step2 = Acc(pred_test>0.5,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((linear_step2-linear_all),1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "falis forward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "falis forward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "succes backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "falis forward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "fails backward\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "Best Validation Acc: 97.3 %\n",
      "선택된 변수의 개수: 63 개\n",
      "succes forward: 0\n",
      "succes backward: 5\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델에 대한 전진 선택법2 적용 결과\n",
    "model, inmodel = variable_selection(LogisticRegression(solver=\"lbfgs\",max_iter=300), X_train,y_train,X_val,y_val,direction=\"step2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델-단계적 선택법2\n",
      "Accuracy: 95.4 %\n",
      "선택된 변수 개수: 63\n",
      "Acc 증감: 0.2 %\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델 단계적 선택법2 적용시 평가 데이터 셋에 대한 결과 확인\n",
    "pred_test = model.predict(X_test.iloc[:,inmodel])\n",
    "print(\"로지스틱 회귀 모델-단계적 선택법2\")\n",
    "logistic_step2 = Acc(pred_test,y_test)\n",
    "print(\"선택된 변수 개수:\", len(inmodel))\n",
    "print(\"Acc 증감:\",round((logistic_step2-logistic_all)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 변수 선택법 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_selection(model, X_train,y_train,X_val,y_val,direction):\n",
    "    var = list(range(len(X_train.columns)))\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    ### 전진 선택법\n",
    "    if direction == \"forward\":\n",
    "        inmodel  =[]\n",
    "        outmodel = var\n",
    "        while outmodel and current_score==best_new_score:\n",
    "            score_candidate = []\n",
    "            for candidate in outmodel:\n",
    "                temp_var = inmodel + [candidate]\n",
    "                Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                model.fit(Temp_X_train,y_train)\n",
    "                prediction = model.predict(Temp_X_val)\n",
    "                score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                score_candidate.append((score,candidate))\n",
    "              \n",
    "            score_candidate.sort()\n",
    "            best_new_score, best_candidate = score_candidate.pop()\n",
    "            if current_score>=best_new_score:\n",
    "                print(inmodel)\n",
    "                break\n",
    "            else:\n",
    "                outmodel.remove(best_candidate)\n",
    "                inmodel.append(best_candidate)\n",
    "                current_score = best_new_score\n",
    "            \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round((score)*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "    \n",
    "    ###후진 소거법\n",
    "    if direction == \"backward\":\n",
    "        inmodel  = var\n",
    "        outmodel = []\n",
    "        while inmodel and current_score==best_new_score:\n",
    "            score_candidate = []\n",
    "            for candidate in inmodel:\n",
    "                temp_var = inmodel.copy()\n",
    "                temp_var.remove(candidate)\n",
    "                Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                model.fit(Temp_X_train,y_train)\n",
    "                prediction = model.predict(Temp_X_val)\n",
    "                score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                score_candidate.append((score,candidate))\n",
    "              \n",
    "            score_candidate.sort()\n",
    "            best_new_score, best_candidate = score_candidate.pop()\n",
    "            \n",
    "            if current_score>=best_new_score:\n",
    "                print(inmodel)\n",
    "                break\n",
    "            else:\n",
    "                outmodel.append(best_candidate)\n",
    "                inmodel.remove(best_candidate)\n",
    "                current_score = best_new_score\n",
    "                \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round((score)*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "        \n",
    "    ###단계적 선택법\n",
    "    if direction == \"step\":\n",
    "        inmodel  =[]\n",
    "        outmodel = var\n",
    "        stop = 0\n",
    "        count = 0\n",
    "        forward = 0\n",
    "        backward = 0\n",
    "        while outmodel and stop<2:\n",
    "            score_candidate = []\n",
    "            count=count+1\n",
    "            if count%2==1 or count==2:\n",
    "                for candidate in outmodel:\n",
    "                    temp_var = inmodel + [candidate]\n",
    "                    Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                    Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                    model.fit(Temp_X_train,y_train)\n",
    "                    prediction = model.predict(Temp_X_val)\n",
    "                    score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                    score_candidate.append((score,candidate))\n",
    "              \n",
    "                score_candidate.sort()\n",
    "                best_new_score, best_candidate = score_candidate.pop()\n",
    "                if current_score<best_new_score:\n",
    "                    print(\"succes forward\")\n",
    "                    outmodel.remove(best_candidate)\n",
    "                    inmodel.append(best_candidate)\n",
    "                    current_score = best_new_score\n",
    "                    stop=0\n",
    "                    forward = forward+1\n",
    "                else:\n",
    "                    print(\"falis forward\")\n",
    "                    stop=stop+1\n",
    "            else:\n",
    "                for candidate in inmodel:\n",
    "                    temp_var = inmodel.copy()\n",
    "                    temp_var.remove(candidate)\n",
    "                    Temp_X_train = X_train.iloc[:,temp_var]\n",
    "                    Temp_X_val   = X_val.iloc[:,temp_var]\n",
    "                    model.fit(Temp_X_train,y_train)\n",
    "                    prediction = model.predict(Temp_X_val)\n",
    "                    score = Acc(prediction>0.5,y_val,pri=False)\n",
    "                    score_candidate.append((score,candidate))\n",
    "                \n",
    "                score_candidate.sort()\n",
    "                best_new_score, best_candidate = score_candidate.pop()\n",
    "                    \n",
    "                if current_score<best_new_score:\n",
    "                    print(\"succes backward\")\n",
    "                    outmodel.append(best_candidate)\n",
    "                    inmodel.remove(best_candidate)\n",
    "                    current_score = best_new_score\n",
    "                    stop=0\n",
    "                    backward = backward+1\n",
    "                else:\n",
    "                    print(\"fails backward\")\n",
    "                    stop=stop+1\n",
    "                \n",
    "            print(inmodel)\n",
    "            \n",
    "        Temp_X_train = X_train.iloc[:,inmodel]\n",
    "        Temp_X_val   = X_val.iloc[:,inmodel]\n",
    "        model.fit(Temp_X_train,y_train)\n",
    "        prediction = model.predict(Temp_X_val)\n",
    "        score = Acc(prediction>0.5,y_val,pri=False)\n",
    "        print(\"Best Validation Acc:\",round((score)*100,1),\"%\")\n",
    "        print(\"선택된 변수의 개수:\",len(inmodel),\"개\")\n",
    "        print(\"succes forward:\", forward)\n",
    "        print(\"succes backward:\", backward)\n",
    "        \n",
    "    return model, inmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\n",
      "[20, 46]\n",
      "[20, 46, 65]\n",
      "[20, 46, 65, 43]\n",
      "[20, 46, 65, 43, 67]\n",
      "[20, 46, 65, 43, 67, 22]\n",
      "[20, 46, 65, 43, 67, 22, 55]\n",
      "[20, 46, 65, 43, 67, 22, 55, 58]\n",
      "[20, 46, 65, 43, 67, 22, 55, 58]\n",
      "Best Validation Acc: 96.0 %\n",
      "선택된 변수의 개수: 8 개\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "model, inmodel = variable_selection(LogisticRegression(solver=\"lbfgs\",max_iter=300), X_train,y_train,X_val,y_val,direction=\"forward\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
